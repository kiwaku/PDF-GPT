{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from getpass import getpass\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "#arg to return source document = true\n",
    "#langchain search gpt enabled\n",
    "from langchain import OpenAI \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.document_loaders import PagedPDFSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from PyPDF2 import PdfReader\n",
    "#Additional\n",
    "import logging\n",
    "import fitz\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "#Directory\n",
    "file = 'America Before Columbus chapter 1.pdf'\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "page_number = \"1\"\n",
    "page_citation = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#from langchain.document_loaders import TextLoader\n",
    "\n",
    "def process_file(dir):\n",
    "    # elevate an error if API key isnâ€™t supplied\n",
    "    # Load the PDF file utilizing PyPDFLoader\n",
    "    loader = PyPDFLoader(dir)\n",
    "    documents = loader.load()\n",
    "\n",
    "    #   Initialize OpenAIEmbeddings for textual content embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # Create a ConversationalRetrievalChain with ChatOpenAI language mannequin\n",
    "    # and PDF search retriever\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    pdfsearch = DeepLake.from_documents(texts, embeddings,)\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.3),\n",
    "    retriever = pdfsearch.as_retriever(search_kwargs={'ok': 1}),\n",
    "    return_source_documents=True,)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_response(past_h, question, btn):\n",
    "#    COUNT, N, chat_history\n",
    "#    end_result = chain({\"query\": question, 'chat_history':chat_history}, return_only_outputs=True)\n",
    "#    chat_history += [(query, result[\"answer\"])]\n",
    "#    N = record(end result['source_documents'][0])[1][1]['page']\n",
    "#    return history, history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Picture rendering\n",
    "def render_file(file, N):\n",
    "    \"\"\"\n",
    "    Function to render a specific page of a PDF file as an image\n",
    "    \"\"\"\n",
    "    logging.info(\"Rendering File...\")\n",
    "    #global N, dir\n",
    "    #file = dir\n",
    "    doc = fitz.open(file)\n",
    "    page = doc[N]\n",
    "    # Render the page as a PNG image with a resolution of 300 DPI\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))\n",
    "    image = Image.frombytes('RGB', [pix.width, pix.height], pix.samples)\n",
    "    logging.info(\"Rendering File Completed...\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"give me one General Travel Safety Tip\"\n",
    "chain = process_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAISS from doc or \n",
    "#retriever = pdfsearch.as_retriever()\n",
    "#retriever.search_kwargs[\"distance_metric\"] = \"cos\"\n",
    "#retriever.search_kwargs[\"fetch_k\"] = 20\n",
    "#retriever.search_kwargs[\"maximal_marginal_relevance\"] = True\n",
    "#retriever.search_kwargs[\"k\"] = 20\n",
    "\n",
    "#chain = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.3),\n",
    "#retriever = pdfsearch.as_retriever(search_kwargs={'ok': 1}),return_source_documents=True,)\n",
    "\n",
    "#chat_history = []\n",
    "#questions = [\"give me one General Travel Safety Tip\"]\n",
    "#def answer(questions):\n",
    "#    for question in questions:\n",
    "#        result = chain({\"question\": question, \"chat_history\": chat_history})\n",
    "#        chat_history.append((question, result[\"answer\"]))\n",
    "#        print(f\"-> **Question**: {question} \\n\")\n",
    "#        print(f\"**Answer**: {result['answer']} \\n\")\n",
    "\n",
    "#print(answer())\n",
    "\n",
    "\n",
    "def generate_answer(user_input):\n",
    "    # Generate response using ChatGPT model\n",
    "    result = chain({\"question\": user_input, \"chat_history\": chat_history})\n",
    "    chat_history.append((user_input, result[\"answer\"]))\n",
    "    source_documents = result['source_documents']\n",
    "\n",
    "    for document in source_documents:\n",
    "        page_number = document.metadata['page']\n",
    "        page_citation = document.metadata['source']\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_answer(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gradio interface\n",
    "#def chat_interface(user_input):\n",
    "    # Process user input using LangChain agent\n",
    "    #langchain_output = langchain_agent.process_input(user_input)\n",
    "\n",
    "\n",
    "    # Print or use the page number as needed\n",
    "        #print(f\"Source name: {page_citation}\")\n",
    "        #print(f\"Page number: {page_number}\")\n",
    "\n",
    "    #global page_number, page_citation\n",
    "    #chatgpt_response = generate_answer(user_input)\n",
    "\n",
    "    #return the image\n",
    "    #render_file(file, page_number)\n",
    "\n",
    "    # Return the response\n",
    "    #source_documents = chatgpt_response['source_documents']\n",
    "\n",
    "    #for document in source_documents:\n",
    "        #page_number = document.metadata['page']\n",
    "        #page_citation = document.metadata['source']\n",
    "    #response = chatgpt_response['answer']\n",
    "    #return response\n",
    "\n",
    "#gr.Interface(fn=chat_interface, inputs=\"text\", outputs=\"text\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#gr.Image(render_file(file, page_number))\n",
    "def chat_interface(user_input):\n",
    "    global page_number, page_citation\n",
    "    chatgpt_response = generate_answer(user_input)\n",
    "    source_documents = chatgpt_response['source_documents']\n",
    "    for document in source_documents:\n",
    "        page_number = document.metadata['page']\n",
    "        page_citation = document.metadata['source']\n",
    "        response = chatgpt_response['answer'] + \"\\n\" +\"\\nCitations: \" + page_citation + \"\\n\" +\"page\" + str(page_number)\n",
    "    return response\n",
    "\n",
    "page_number = 0\n",
    "\n",
    "def showpic():\n",
    "    return render_file(file, page_number)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            text1 = gr.Textbox(label=\"Ask a question about the document\")\n",
    "            text2 = gr.Textbox(label=\"Output\")\n",
    "            btn = gr.Button(\"Run\")\n",
    "\n",
    "\n",
    "\n",
    "        print(page_citation, \"page\" + str(page_number))\n",
    "        with gr.Column(scale=2, min_width=600):\n",
    "            img1 = gr.Image(showpic())\n",
    "            \n",
    "        #btn to reload sources could also be good\n",
    "        btn.click(fn=chat_interface, inputs=text1, outputs=text2).success(fn=showpic, inputs=[], outputs=[img1])\n",
    "        #img1.change(, text1, text2)\n",
    "        #text1.submit(chat_interface(), [text1, text2], [text1, text2])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
